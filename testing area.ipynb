{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Northwind database\n",
    "##### Jonathan Tyler\n",
    "\n",
    "Northwind is a company that sells specialty foods. I was given a mandate to  \"__do something with this database__\" as my first project as a new hire. Unfortunatly at the end of last week, the whole computer science division got sick. It was someone's birthday and they all ate bad sheet cake. I wasn't aware those could *actually* go bad.\n",
    "\n",
    "I was able to find a entity-relation diagram for the database but not much else. So to break down this task:\n",
    "1. First I am going to have to explore the database myself to see the basic metrics of the company.\n",
    "2. Then I will use this basic data to formulate some hypotheses concerning some underlying trends.\n",
    "3. Finally I will attempt to test out these ideas to prove myself right or wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy.orm import Session, sessionmaker\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "from scipy.stats import ttest_1samp, ttest_ind\n",
    "from scipy.stats import levene, shapiro, mannwhitneyu, kruskal\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting the database enable to start looking at the data. I plan to compare the ERD to the database and get basic metric from the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:00,203 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2019-02-01 13:04:00,205 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-02-01 13:04:00,207 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2019-02-01 13:04:00,208 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-02-01 13:04:00,210 INFO sqlalchemy.engine.base.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2019-02-01 13:04:00,210 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Category',\n",
       " 'Customer',\n",
       " 'CustomerCustomerDemo',\n",
       " 'CustomerDemographic',\n",
       " 'Employee',\n",
       " 'EmployeeTerritory',\n",
       " 'Order',\n",
       " 'OrderDetail',\n",
       " 'Product',\n",
       " 'Region',\n",
       " 'Shipper',\n",
       " 'Supplier',\n",
       " 'Territory']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#engine = create_engine('sqlite:///Northwind_large.sqlite', echo=True)\n",
    "engine = create_engine('sqlite:///Northwind_small.sqlite', echo=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "inspector = inspect(engine) #checking the ERD against the actual database\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So found my first discrepancy, most the table names are stated as singular while the ERD have them as plural.  \n",
    "  \n",
    "I will submit a ticket to the department to fix this when they get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:00,221 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"Product\")\n",
      "2019-02-01 13:04:00,222 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Id',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': True,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 1},\n",
       " {'name': 'ProductName',\n",
       "  'type': VARCHAR(length=8000),\n",
       "  'nullable': True,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'SupplierId',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'CategoryId',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'QuantityPerUnit',\n",
       "  'type': VARCHAR(length=8000),\n",
       "  'nullable': True,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'UnitPrice',\n",
       "  'type': DECIMAL(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'UnitsInStock',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'UnitsOnOrder',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'ReorderLevel',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0},\n",
       " {'name': 'Discontinued',\n",
       "  'type': INTEGER(),\n",
       "  'nullable': False,\n",
       "  'default': None,\n",
       "  'autoincrement': 'auto',\n",
       "  'primary_key': 0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector.get_columns('Product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit messy, I recall a function that I had used previously that I could use to help in cleaning this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_info(col_name): #quick function based on https://github.com/learn-co-curriculum/dsc-2-13-11-queries-with-sqlalchemy-lab\n",
    "    col_list = inspector.get_columns(col_name)\n",
    "    print(f'Table Name: {col_name} \\n')\n",
    "    \n",
    "    for col in col_list:\n",
    "        if col['primary_key'] == 1:\n",
    "            print(f\"{col['name']}  ||PRIMARY KEY||  dtype: {col['type']}\")\n",
    "        else:\n",
    "            print(f\"{col['name']}     dtype: {col['type']}\")\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name: Product \n",
      "\n",
      "Id  ||PRIMARY KEY||  dtype: INTEGER\n",
      "ProductName     dtype: VARCHAR(8000)\n",
      "SupplierId     dtype: INTEGER\n",
      "CategoryId     dtype: INTEGER\n",
      "QuantityPerUnit     dtype: VARCHAR(8000)\n",
      "UnitPrice     dtype: DECIMAL\n",
      "UnitsInStock     dtype: INTEGER\n",
      "UnitsOnOrder     dtype: INTEGER\n",
      "ReorderLevel     dtype: INTEGER\n",
      "Discontinued     dtype: INTEGER\n"
     ]
    }
   ],
   "source": [
    "get_column_info('Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:00,355 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"Employee\")\n",
      "2019-02-01 13:04:00,358 INFO sqlalchemy.engine.base.Engine ()\n",
      "Table Name: Employee \n",
      "\n",
      "Id  ||PRIMARY KEY||  dtype: INTEGER\n",
      "LastName     dtype: VARCHAR(8000)\n",
      "FirstName     dtype: VARCHAR(8000)\n",
      "Title     dtype: VARCHAR(8000)\n",
      "TitleOfCourtesy     dtype: VARCHAR(8000)\n",
      "BirthDate     dtype: VARCHAR(8000)\n",
      "HireDate     dtype: VARCHAR(8000)\n",
      "Address     dtype: VARCHAR(8000)\n",
      "City     dtype: VARCHAR(8000)\n",
      "Region     dtype: VARCHAR(8000)\n",
      "PostalCode     dtype: VARCHAR(8000)\n",
      "Country     dtype: VARCHAR(8000)\n",
      "HomePhone     dtype: VARCHAR(8000)\n",
      "Extension     dtype: VARCHAR(8000)\n",
      "Photo     dtype: BLOB\n",
      "Notes     dtype: VARCHAR(8000)\n",
      "ReportsTo     dtype: INTEGER\n",
      "PhotoPath     dtype: VARCHAR(8000)\n"
     ]
    }
   ],
   "source": [
    "get_column_info('Employee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:00,380 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"Supplier\")\n",
      "2019-02-01 13:04:00,381 INFO sqlalchemy.engine.base.Engine ()\n",
      "Table Name: Supplier \n",
      "\n",
      "Id  ||PRIMARY KEY||  dtype: INTEGER\n",
      "CompanyName     dtype: VARCHAR(8000)\n",
      "ContactName     dtype: VARCHAR(8000)\n",
      "ContactTitle     dtype: VARCHAR(8000)\n",
      "Address     dtype: VARCHAR(8000)\n",
      "City     dtype: VARCHAR(8000)\n",
      "Region     dtype: VARCHAR(8000)\n",
      "PostalCode     dtype: VARCHAR(8000)\n",
      "Country     dtype: VARCHAR(8000)\n",
      "Phone     dtype: VARCHAR(8000)\n",
      "Fax     dtype: VARCHAR(8000)\n",
      "HomePage     dtype: VARCHAR(8000)\n"
     ]
    }
   ],
   "source": [
    "get_column_info('Supplier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "So a quick check of the different tables align with the ERD. That is good. But I should be checking out the individual tables before calling them nevertheless, it is good pratice.\n",
    "  \n",
    "Now lets start checking out a few things:\n",
    "- How much of what are we selling?\n",
    "- Who are our main suppliers?\n",
    "- What does our customer base look like?\n",
    "- What is the geographical spread of our workforce?\n",
    "\n",
    "Once we know these things, we will have a broad overview of the business. From there we will investigate any abnormalities or go splunking for underlying trends.\n",
    "___\n",
    "---\n",
    "Now lets make a connection to the engine and make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = engine.connect() #connecting the engine to be able to make queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:00,459 INFO sqlalchemy.engine.base.Engine SELECT * FROM [Order]\n",
      "2019-02-01 13:04:00,461 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>EmployeeId</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>RequiredDate</th>\n",
       "      <th>ShippedDate</th>\n",
       "      <th>ShipVia</th>\n",
       "      <th>Freight</th>\n",
       "      <th>ShipName</th>\n",
       "      <th>ShipAddress</th>\n",
       "      <th>ShipCity</th>\n",
       "      <th>ShipRegion</th>\n",
       "      <th>ShipPostalCode</th>\n",
       "      <th>ShipCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10248</td>\n",
       "      <td>VINET</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-07-04</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>3</td>\n",
       "      <td>32.38</td>\n",
       "      <td>Vins et alcools Chevalier</td>\n",
       "      <td>59 rue de l'Abbaye</td>\n",
       "      <td>Reims</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>51100</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10249</td>\n",
       "      <td>TOMSP</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-07-05</td>\n",
       "      <td>2012-08-16</td>\n",
       "      <td>2012-07-10</td>\n",
       "      <td>1</td>\n",
       "      <td>11.61</td>\n",
       "      <td>Toms Spezialitäten</td>\n",
       "      <td>Luisenstr. 48</td>\n",
       "      <td>Münster</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>44087</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10250</td>\n",
       "      <td>HANAR</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-07-08</td>\n",
       "      <td>2012-08-05</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>2</td>\n",
       "      <td>65.83</td>\n",
       "      <td>Hanari Carnes</td>\n",
       "      <td>Rua do Paço, 67</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>South America</td>\n",
       "      <td>05454-876</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10251</td>\n",
       "      <td>VICTE</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-07-08</td>\n",
       "      <td>2012-08-05</td>\n",
       "      <td>2012-07-15</td>\n",
       "      <td>1</td>\n",
       "      <td>41.34</td>\n",
       "      <td>Victuailles en stock</td>\n",
       "      <td>2, rue du Commerce</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>69004</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10252</td>\n",
       "      <td>SUPRD</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-07-09</td>\n",
       "      <td>2012-08-06</td>\n",
       "      <td>2012-07-11</td>\n",
       "      <td>2</td>\n",
       "      <td>51.30</td>\n",
       "      <td>Suprêmes délices</td>\n",
       "      <td>Boulevard Tirou, 255</td>\n",
       "      <td>Charleroi</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>B-6000</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id CustomerId  EmployeeId   OrderDate RequiredDate ShippedDate  ShipVia  \\\n",
       "0  10248      VINET           5  2012-07-04   2012-08-01  2012-07-16        3   \n",
       "1  10249      TOMSP           6  2012-07-05   2012-08-16  2012-07-10        1   \n",
       "2  10250      HANAR           4  2012-07-08   2012-08-05  2012-07-12        2   \n",
       "3  10251      VICTE           3  2012-07-08   2012-08-05  2012-07-15        1   \n",
       "4  10252      SUPRD           4  2012-07-09   2012-08-06  2012-07-11        2   \n",
       "\n",
       "   Freight                   ShipName           ShipAddress        ShipCity  \\\n",
       "0    32.38  Vins et alcools Chevalier    59 rue de l'Abbaye           Reims   \n",
       "1    11.61         Toms Spezialitäten         Luisenstr. 48         Münster   \n",
       "2    65.83              Hanari Carnes       Rua do Paço, 67  Rio de Janeiro   \n",
       "3    41.34       Victuailles en stock    2, rue du Commerce            Lyon   \n",
       "4    51.30           Suprêmes délices  Boulevard Tirou, 255       Charleroi   \n",
       "\n",
       "       ShipRegion ShipPostalCode ShipCountry  \n",
       "0  Western Europe          51100      France  \n",
       "1  Western Europe          44087     Germany  \n",
       "2   South America      05454-876      Brazil  \n",
       "3  Western Europe          69004      France  \n",
       "4  Western Europe         B-6000     Belgium  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = '''SELECT * FROM [Order]''' #simple query\n",
    "df_order = pd.read_sql_query(q, engine) #puts the information from the query into a dataframe\n",
    "df_order.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantasic, now lets start flushing out answers to those inital questions\n",
    "\n",
    "## How much of what are we selling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the Product table and the Order Detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name: Product \n",
      "\n",
      "Id  ||PRIMARY KEY||  dtype: INTEGER\n",
      "ProductName     dtype: VARCHAR(8000)\n",
      "SupplierId     dtype: INTEGER\n",
      "CategoryId     dtype: INTEGER\n",
      "QuantityPerUnit     dtype: VARCHAR(8000)\n",
      "UnitPrice     dtype: DECIMAL\n",
      "UnitsInStock     dtype: INTEGER\n",
      "UnitsOnOrder     dtype: INTEGER\n",
      "ReorderLevel     dtype: INTEGER\n",
      "Discontinued     dtype: INTEGER\n",
      "None\n",
      "2019-02-01 13:04:00,564 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"OrderDetail\")\n",
      "2019-02-01 13:04:00,566 INFO sqlalchemy.engine.base.Engine ()\n",
      "Table Name: OrderDetail \n",
      "\n",
      "Id  ||PRIMARY KEY||  dtype: VARCHAR(8000)\n",
      "OrderId     dtype: INTEGER\n",
      "ProductId     dtype: INTEGER\n",
      "UnitPrice     dtype: DECIMAL\n",
      "Quantity     dtype: INTEGER\n",
      "Discount     dtype: FLOAT\n",
      "None\n",
      "2019-02-01 13:04:00,570 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"Category\")\n",
      "2019-02-01 13:04:00,571 INFO sqlalchemy.engine.base.Engine ()\n",
      "Table Name: Category \n",
      "\n",
      "Id  ||PRIMARY KEY||  dtype: INTEGER\n",
      "CategoryName     dtype: VARCHAR(8000)\n",
      "Description     dtype: VARCHAR(8000)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_column_info('Product'))\n",
    "print(get_column_info('OrderDetail'))\n",
    "print(get_column_info('Category'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the table is ERD is wrong again. Some of the tables are incorrectly stated i.e. ProductID is just Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:00,587 INFO sqlalchemy.engine.base.Engine SELECT p.ProductName, c.CategoryName, SUM(o.Quantity) num_ordered FROM Product p LEFT JOIN OrderDetail o ON o.ProductId = p.Id LEFT JOIN Category c ON c.Id = p.CategoryId GROUP BY p.ProductName ORDER BY num_ordered DESC\n",
      "2019-02-01 13:04:00,588 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>num_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camembert Pierrot</td>\n",
       "      <td>Dairy Products</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raclette Courdavault</td>\n",
       "      <td>Dairy Products</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gorgonzola Telino</td>\n",
       "      <td>Dairy Products</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gnocchi di nonna Alice</td>\n",
       "      <td>Grains/Cereals</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pavlova</td>\n",
       "      <td>Confections</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ProductName    CategoryName  num_ordered\n",
       "0       Camembert Pierrot  Dairy Products         1577\n",
       "1    Raclette Courdavault  Dairy Products         1496\n",
       "2       Gorgonzola Telino  Dairy Products         1397\n",
       "3  Gnocchi di nonna Alice  Grains/Cereals         1263\n",
       "4                 Pavlova     Confections         1158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q='''SELECT p.ProductName, c.CategoryName, SUM(o.Quantity) num_ordered \\\n",
    "FROM Product p \\\n",
    "LEFT JOIN OrderDetail o ON o.ProductId = p.Id \\\n",
    "LEFT JOIN Category c ON c.Id = p.CategoryId \\\n",
    "GROUP BY p.ProductName ORDER BY num_ordered DESC'''\n",
    "df1 = pd.read_sql_query(q, engine)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confections       13\n",
       "Condiments        12\n",
       "Seafood           12\n",
       "Beverages         12\n",
       "Dairy Products    10\n",
       "Grains/Cereals     7\n",
       "Meat/Poultry       6\n",
       "Produce            5\n",
       "Name: CategoryName, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.CategoryName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:35,667 INFO sqlalchemy.engine.base.Engine SELECT * FROM OrderDetail\n",
      "2019-02-01 13:04:35,668 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OrderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10248/11</td>\n",
       "      <td>10248</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10248/42</td>\n",
       "      <td>10248</td>\n",
       "      <td>42</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10248/72</td>\n",
       "      <td>10248</td>\n",
       "      <td>72</td>\n",
       "      <td>34.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10249/14</td>\n",
       "      <td>10249</td>\n",
       "      <td>14</td>\n",
       "      <td>18.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10249/51</td>\n",
       "      <td>10249</td>\n",
       "      <td>51</td>\n",
       "      <td>42.4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  OrderId  ProductId  UnitPrice  Quantity  Discount\n",
       "0  10248/11    10248         11       14.0        12       0.0\n",
       "1  10248/42    10248         42        9.8        10       0.0\n",
       "2  10248/72    10248         72       34.8         5       0.0\n",
       "3  10249/14    10249         14       18.6         9       0.0\n",
       "4  10249/51    10249         51       42.4        40       0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q='''SELECT * FROM OrderDetail'''\n",
    "df_od = pd.read_sql_query(q, engine)\n",
    "df_od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-01 13:04:34,050 INFO sqlalchemy.engine.base.Engine SELECT * FROM Product\n",
      "2019-02-01 13:04:34,050 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>SupplierId</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>QuantityPerUnit</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>UnitsInStock</th>\n",
       "      <th>UnitsOnOrder</th>\n",
       "      <th>ReorderLevel</th>\n",
       "      <th>Discontinued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chai</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>18.00</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chang</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24 - 12 oz bottles</td>\n",
       "      <td>19.00</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aniseed Syrup</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12 - 550 ml bottles</td>\n",
       "      <td>10.00</td>\n",
       "      <td>13</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chef Anton's Cajun Seasoning</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48 - 6 oz jars</td>\n",
       "      <td>22.00</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chef Anton's Gumbo Mix</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36 boxes</td>\n",
       "      <td>21.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                   ProductName  SupplierId  CategoryId  \\\n",
       "0   1                          Chai           1           1   \n",
       "1   2                         Chang           1           1   \n",
       "2   3                 Aniseed Syrup           1           2   \n",
       "3   4  Chef Anton's Cajun Seasoning           2           2   \n",
       "4   5        Chef Anton's Gumbo Mix           2           2   \n",
       "\n",
       "       QuantityPerUnit  UnitPrice  UnitsInStock  UnitsOnOrder  ReorderLevel  \\\n",
       "0   10 boxes x 20 bags      18.00            39             0            10   \n",
       "1   24 - 12 oz bottles      19.00            17            40            25   \n",
       "2  12 - 550 ml bottles      10.00            13            70            25   \n",
       "3       48 - 6 oz jars      22.00            53             0             0   \n",
       "4             36 boxes      21.35             0             0             0   \n",
       "\n",
       "   Discontinued  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q='''SELECT * FROM Product'''\n",
    "df_prod = pd.read_sql_query(q, engine)\n",
    "df_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod.set_index('Id',inplace=True)\n",
    "df_od.set_index('ProductId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod = df_prod.sort_index()\n",
    "df_od = df_od.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1    -3.6\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1    -3.6\n",
       "1    -3.6\n",
       "1    -3.6\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1    -3.6\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1     0.0\n",
       "1    -3.6\n",
       "1     0.0\n",
       "     ... \n",
       "77   -2.6\n",
       "77   -2.6\n",
       "77    0.0\n",
       "77    0.0\n",
       "77   -2.6\n",
       "77   -2.6\n",
       "77   -2.6\n",
       "77   -2.6\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77    0.0\n",
       "77   -2.6\n",
       "77   -2.6\n",
       "77    0.0\n",
       "77    0.0\n",
       "Name: UnitPrice, Length: 2155, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_od.UnitPrice - df_prod.UnitPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains order details on 2155 items ordered by different companies. Also looks like confections is the kind of food we have the most orders for.\n",
    "\n",
    "## Who are our main suppliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_column_info('Order'))\n",
    "print(get_column_info('Supplier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT s.CompanyName, s.Region, COUNT(*) num_of_orders FROM [Order] o \\\n",
    "LEFT JOIN OrderDetail od ON o.Id = od.OrderId \\\n",
    "LEFT JOIN Product p ON od.ProductId = p.Id \\\n",
    "LEFT JOIN Supplier s ON p.SupplierId = s.Id \\\n",
    "GROUP BY s.CompanyName \\\n",
    "ORDER BY num_of_orders DESC'''\n",
    "\n",
    "df2 = pd.read_sql_query(q, engine)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Region.value_counts(), df2.num_of_orders.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest amount of orders come from Western Europe and it is one of the largest portion of our supply chain.\n",
    "\n",
    "## What does our customer base look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_column_info('CustomerDemographic'))\n",
    "print(get_column_info('Customer'))\n",
    "print(get_column_info('CustomerCustomerDemo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT * FROM CustomerCustomerDemo'''\n",
    "\n",
    "df3 = pd.read_sql_query(q, engine)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `CustomerCustomerDemo` is an empty table. This must be a new table or something went wrong. That means the only customer data I have to look at will from the customer table. Another ticket I need to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT ContactTitle, Count(*) num_of_types \\\n",
    "FROM Customer  \\\n",
    "GROUP BY ContactTitle  \\\n",
    "ORDER BY num_of_types DESC'''\n",
    "\n",
    "df4 = pd.read_sql_query(q, engine)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT Region, Count(*) num_of_customers \\\n",
    "FROM Customer  \\\n",
    "GROUP BY Region  \\\n",
    "ORDER BY num_of_customers DESC'''\n",
    "\n",
    "df5 = pd.read_sql_query(q, engine)\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good to see our supplier network lines up with our supply chain. Also intriguing to see what are the title of our contacts. Now finally to answer our last question.\n",
    "\n",
    "## What is the geographical spread of our workforce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_column_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f8d4aed51370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_column_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Territory'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_column_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Region'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_column_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EmployeeTerritory'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_column_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Employee'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_column_info' is not defined"
     ]
    }
   ],
   "source": [
    "print(get_column_info('Territory'))\n",
    "print(get_column_info('Region'))\n",
    "print(get_column_info('EmployeeTerritory'))\n",
    "print(get_column_info('Employee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT e.LastName, e.Title, e.Region as based_from, r.RegionDescription FROM Employee e \\\n",
    "LEFT JOIN EmployeeTerritory et ON e.Id = et.EmployeeId \\\n",
    "LEFT JOIN Territory t ON et.TerritoryId = t.Id \\\n",
    "LEFT JOIN Region r ON t.RegionId = r.Id \\\n",
    "GROUP BY e.LastName \\\n",
    "ORDER BY e.Title'''\n",
    "\n",
    "df6 = pd.read_sql_query(q, engine)\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unclear what \"RegionDescription\" from the `Region` table represents. I will need to do talk to one of the database engineers when they get back for some clarification.\n",
    "\n",
    "So now we have a brief overview of the company, we can start some hypothesis testing.\n",
    "___\n",
    "___\n",
    "# Hypothesis Testing\n",
    "1) Do discounts have a statistically significant effect on the number of products customers order? If so, at what level(s) of discount?  \n",
    "2) Is there a difference in the money generated from sales between the North America office and the British Island office?  \n",
    "3) Does having 'manager' in your title effect the amount a customer orders?  \n",
    "4) Is there a difference in quantity of products given their average shelf life?\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Do discounts have a statistically significant effect on the number of products customers order? If so, at what level(s) of discount?\n",
    "\n",
    "### 1-1 Initial Analysis\n",
    "This was the one objective that I was given to solve using this database. I will gather the population metrics ($\\mu, \\sigma$) form the total number of products ordered. Then I will break up the orders into two groups (items with discount and items without a discount) and compare the two groups. For the hypothesis testing, I plan on using a one tailed test. People who plan on ordering a product won't order a smaller quantity solely because it cost less; therefore, there is little logic in using a two tailed test. \n",
    "  \n",
    "If there is a significant result, I will further test out if there is a level of discount that sells more products.  \n",
    "\n",
    "$H_{o}$: There is no difference in the number of products customers order given there is a discount  \n",
    "$H_{a}$: There is an increase in the number of products customers order given there is a discount  \n",
    "$\\alpha = .05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT OrderId, ProductId, Discount FROM OrderDetail'''\n",
    "\n",
    "df = pd.read_sql_query(q, engine)\n",
    "df.head(15)#, df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like when Northwind Traders gives a discount to an order, it doesn't always apply across the whole order. Nor does the same discount level apply across the whole order. That means I have to reorganize my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Discount.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Northwind provides discount at a lot of different tiers. Grouping by order, I will take the largest amount of discount given. I am hoping this helps me bin the data into manageable subsections. Lets see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_nums = df.OrderId.unique() #Gives the unique order number\n",
    "\n",
    "\n",
    "#The below uses dictionary comprehension to create a dictionary that I will transform into a dataframe\n",
    "#I matched the order number to orginal df. It counts how many rows/products made in that order.\n",
    "#Then I found the max value of the discount given product-wise\n",
    "dict_for_df = {num : [len(df[df.OrderId == num]), df.Discount[df.OrderId == num].max()] for num in order_nums}\n",
    "\n",
    "df_order = pd.DataFrame.from_dict(dict_for_df, orient='index') #orient=index makes the keys of the dict be the index\n",
    "\n",
    "df_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.reset_index(inplace=True) #reset the index, but keeping the orginal one in a new column\n",
    "df_order.columns = ['id', 'num_of_items', 'lvl_of_disc'] #renaming to what they are\n",
    "df_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a check to make sure I got everything from the orginal table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_order.num_of_items) == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at what were the levels of discount offered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.lvl_of_disc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked better than I could have hoped. The orders that were given small discounts (1% - 4%) to individual items, all had at least one item that was offered at 5% discount.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.violinplot(y='num_of_items',x='lvl_of_disc', data=df_order)\n",
    "plt.title('Violin plots: comparing the shape at different levels of discount')\n",
    "plt.xlabel('Max discount given per order')\n",
    "plt.ylabel('Number of items in order');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there seems to be an outlier at 20% discount. Lets take care of that and move onto testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.num_of_items[df_order.lvl_of_disc == .2].max() #finding the max at discount level .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order[df_order.num_of_items == 25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.drop(index=829, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.violinplot(y='num_of_items',x='lvl_of_disc', data=df_order)\n",
    "plt.title('Violin plots: comparing the shape at different levels of discount')\n",
    "plt.xlabel('Max discount given per order')\n",
    "plt.ylabel('Number of items in order')\n",
    "#plt.savefig('violin discount levels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 Testing\n",
    "\n",
    "Since there are multiple groups (levels of discount), an ANOVA test would be the best choice to use. The ANOVA test will show if there is a significant difference between no discount and discount. If there is a significant outcome, I plan on using the Tukey HSD (honestly significant difference) test to determine if the relationship between multiple levels of discount are statistically significant. This will be a post hoc test.\n",
    "\n",
    "\n",
    "#### ANOVA\n",
    " \n",
    "Checking the assumptions for an ANOVA testing. The assumptions apply to the residuals and not the variables themselves.\n",
    "- Independence of cases.\n",
    "- Normality of residuals\n",
    "- Equality (or \"homogeneity\") of variances\n",
    "\n",
    "Independence is met. Different orders from different customers meeting different demands. An ANOVA test is based on the F-statistic which is pretty robust and allows us to suspend some of the assumptions given the group sizes are roughly equal. We can verify the assumptions after the test by using the Levene’s or Omnibus test for homogeneity of variances and either the Jarque-Bera or Shapiro tests for Normality. More on this can be found _[here](https://pythonfordatascience.org/anova-python/)_.\n",
    "\n",
    "Reformatting my hypothesis:  \n",
    "$H_{o} : \\mu_{no \\space discount} = \\mu_{discount}$  \n",
    "$H_{a} : \\mu_{no \\space discount} < \\mu_{discount}$  \n",
    "$\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols('num_of_items ~ C(lvl_of_disc)', data=df_order).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither our Omnibus (homogenity) or Jarque-Bera (normailty) were signifigant meaning our assumptions for our test panned out. \n",
    "\n",
    "So focusing p-value of the F-statisic, it is less than our critical value. So there is a difference between the two groups and that means we have to dig a bit deeper. Finally to check at what level we see the biggest difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MultiComparison(df_order.num_of_items, df_order.lvl_of_disc)\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3 Results\n",
    "\n",
    "- We can reject our null hypothesis that concludes that there is __significant difference__ between discount and no discount (p-value < $\\alpha$ :: 0.0106 < 0.05)  \n",
    "- Comparing between the different levels of discount, the greatest effect is seen at no discount to a 10% discount. \n",
    "- Further testing needs to account for orders with different discount levels within the same order\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Is there a difference in the money generated from sales between the North America office and the British Island office?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The employees of this company are based in two central locations. I want to know if one office is better at business than the other. The metric will be money generated (products ordered * price) with the differential based on one office or another.\n",
    "\n",
    "$H_{o} =$ The employees based out of the British Island office generates the same amount revenue, per order, than the North American office.  \n",
    "$H_{a} =$ The employees based out of the British Island office generates less revenue, per order, than the North American office.  \n",
    "$\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Inital Analysis\n",
    "\n",
    "During my EDA, the information for employee territory not specific for my needs. I will use the region they live in as the seperation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT od.OrderId, SUM(od.UnitPrice*od.Quantity) AS generated, e.Region AS employ_from \\\n",
    "FROM OrderDetail od \\\n",
    "LEFT JOIN [Order] o ON od.OrderId = o.Id \\\n",
    "LEFT JOIN Employee e ON o.EmployeeId = e.Id\n",
    "GROUP BY od.OrderId'''\n",
    "\n",
    "df = pd.read_sql_query(q, engine)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have all 830 orders. Great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('employ_from')['generated'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average made by both offices are close to each other but there is far fewer sales made by the British office. Lets take a quick look at the distribution for both, but look at the above data there is likely to be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist('generated', data=df[df.employ_from == 'North America'], label= 'NA')\n",
    "plt.hist('generated', data=df[df.employ_from == 'British Isles'], label= 'BI')\n",
    "plt.legend()\n",
    "plt.ylabel('Quantities of order')\n",
    "plt.xlabel('Price of order')\n",
    "#plt.savefig('hist money')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a few outliers. Lets take care of the egregious ones i.e. anything above 11K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.generated.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [617,782,733,124,176,569,641,169]\n",
    "df.drop(index=to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brit = df[df.employ_from == 'British Isles']\n",
    "merica = df[df.employ_from == 'North America']\n",
    "brit.describe(), merica.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann–Whitney U test\n",
    "\n",
    "Mann–Whitney U test is a nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample.\n",
    "\n",
    "Unlike the t-test it does not require the assumption of normal distributions. It is nearly as efficient as the t-test on normal distributions.\n",
    "\n",
    "Mann-Whitney assumptions:  \n",
    "1) The dependent variable should be measured on an ordinal scale or a continuous scale.  \n",
    "2) The independent variable should be two independent, categorical groups.  \n",
    "3) Observations should be independent. In other words, there should be no relationship between the two groups or within each group.  \n",
    "4) Observations are not normally distributed. However, they should follow the same shape (i.e. both are bell-shaped and skewed left).  \n",
    "\n",
    "\n",
    "All assumptions are met within our data. So finally, refining our hypothesis: \n",
    "\n",
    "$H_{o} =$ There is no statistical difference between the meadian revenues generated by the North American office and the British Island office.  \n",
    "$H_{a} =$ There is a statistical difference between the meadian revenues generated by the North American office and the British Island office.  \n",
    "$\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merica['generated'].hist(label='American office')\n",
    "brit['generated'].hist(label='British Isle office')\n",
    "plt.title('Histogram of money generate by based on office location')\n",
    "plt.xlabel('Quantity of money')\n",
    "plt.ylabel('Orders count')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('hist of money gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(brit.generated, merica.generated, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent T-test\n",
    "\n",
    "Like every test, this inferential statistic test has assumptions. The assumptions that the data must meet in order for the test results to be valid are:  \n",
    "\n",
    "Independent T-test Assumptions\n",
    "- The samples are independently and randomly drawn\n",
    "- The distribution of the residuals between the two groups should follow the normal distribution\n",
    "- The variances between the two groups are equal\n",
    "\n",
    "The first assumption is met. The second assumption can be suspended given a large enough sample size, therefore independent t-test remains quite robust for violations of normality. [More information](http://thestatsgeek.com/2013/09/28/the-t-test-and-robustness-to-non-normality/) on this topic has been provided.\n",
    "\n",
    "Keep in mind that as a parametric test, the independent t-test delivers best and most reliable results if both groups are normally distributed. Reliability decreases for skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ttest_ind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cba9ecd9d708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mttest_ind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ttest_ind' is not defined"
     ]
    }
   ],
   "source": [
    "ttest_ind(brit.generated, merica.generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Failed to reject the null hypothesis. There is no statistical difference between the median revenues generated by the North American office and the British Island office \n",
    "- (p-value > $\\alpha$ :: 0.3749 > 0.05)  \n",
    "- Further testing: choosing a different metric and test out hypothesis again.\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Does having 'manager' in your title effect the amount a customer orders?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Inital Analysis\n",
    "The customers that we do business with, there are different tiers of titles that they use. I want to know if a manager typically orders more than other customers.\n",
    "\n",
    "$H_{o} =$ Having manager in your title, the amount a customer orders doesn't change  \n",
    "$H_{a} =$ Having manager in your title, the amount a customer orders changes  \n",
    "$\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_info('Customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT c.CompanyName, c.ContactTitle, COUNT(*) AS orders_placed \\\n",
    "FROM OrderDetail od \\\n",
    "LEFT JOIN [Order] o ON od.OrderId = o.Id \\\n",
    "LEFT JOIN Customer c ON c.Id = o.CustomerId \\\n",
    "GROUP BY c.CompanyName'''\n",
    "\n",
    "df = pd.read_sql_query(q, engine)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orders_placed.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, we have all of the orders placed. There seems be a few ghost orders, someone placing some personal orders, or some testing data. Nevertheless, I will need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=0, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now encoding manager title vs no mananger title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_mgmt'] = np.where(df.ContactTitle.str.contains('anager'),1,0) #also could have used .lower() to include the full word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.violinplot(y='orders_placed',x='is_mgmt', data=df)\n",
    "plt.title('Violin plots: comparing the distribution of management vs non-management')\n",
    "plt.xlabel('Is management')\n",
    "plt.ylabel('Number of items in order');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('is_mgmt').orders_placed.idxmax(),df.groupby('is_mgmt').orders_placed.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[66,19], inplace=True)\n",
    "#df.drop(index=[57], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.violinplot(y='orders_placed',x='is_mgmt', data=df)\n",
    "plt.title('Violin plots: comparing the distribution of management vs non-management')\n",
    "plt.xlabel('Is management')\n",
    "plt.ylabel('Number of items in order');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 Testing\n",
    "\n",
    "I will perform both the independent T-test as well as Mann-Whitney U test.  \n",
    "\n",
    "See section 2-2 for supporting documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_yes = df.orders_placed[df.is_mgmt == 1]\n",
    "mgmt_no = df.orders_placed[df.is_mgmt == 0]\n",
    "ttest_ind(mgmt_yes, mgmt_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(mgmt_no, mgmt_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Failed to reject the null hypothesis. As a customer having manager in your title, the quantity ordered _doesn't signifgantly change_ compared to customers without that title  \n",
    "- p-value > $\\alpha$ :: 0.2241 > 0.05\n",
    "- Further testing: change the criteria in which the customers are grouped. Include 'owner' title with the 'manager' title and compare results.\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Is there a difference in quantity of products given their average shelf life?\n",
    "\n",
    "## 4-1 Initial Analysis\n",
    "Northwind Traders sell different types of products. I encode the types of products into perishable vs non-perishable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_{o} =$ The quantity of perishable products ordered is the same as the quantity of non-perishable products ordered  \n",
    "$H_{\\alpha} =$ The quantity of perishable products ordered is the different as the quantity of non-perishable products ordered  \n",
    "$\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_info('OrderDetail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''SELECT od.ProductId AS prod_id, od.Quantity, od.UnitPrice, cat.CategoryName \\\n",
    "FROM OrderDetail od \\\n",
    "LEFT JOIN Product p ON od.ProductId = p.Id \\\n",
    "LEFT JOIN Category cat ON p.CategoryId = cat.Id \\\n",
    "'''\n",
    "\n",
    "df = pd.read_sql_query(q,engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 2155 items in all the orders are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CategoryName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding each different category into perishable/non-perishable where 1 indicates perishable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goes_bad = ['Produce', 'Meat/Poultry', 'Seafood', 'Dairy Products']\n",
    "#non_perish = ['Beverages', 'Condiments', 'Confections', 'Grains/Cereals']\n",
    "\n",
    "def perishable(row):\n",
    "    if row['CategoryName'] == 'Produce':\n",
    "        return 1\n",
    "    if row['CategoryName'] == 'Meat/Poultry':\n",
    "        return 1\n",
    "    if row['CategoryName'] == 'Seafood':\n",
    "        return 1\n",
    "    if row['CategoryName'] == 'Dairy Products':\n",
    "        return 1\n",
    "    if row['CategoryName'] == 'Beverages':\n",
    "        return 0\n",
    "    if row['CategoryName'] == 'Condiments':\n",
    "        return 0\n",
    "    if row['CategoryName'] == 'Confections':\n",
    "        return 0\n",
    "    if row['CategoryName'] == 'Grains/Cereals':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['perish'] = df.apply(lambda row : perishable(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to plot and compare each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.violinplot(y='Quantity',x='perish', data=df)\n",
    "plt.title('Violin plots: comparing the distribution of perishable items')\n",
    "plt.xlabel('Is perishable')\n",
    "plt.ylabel('Quantity ordered')\n",
    "#plt.savefig('vioin perish');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('perish')['Quantity'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, I will perform both the independent T-test as well as Mann-Whitney U test.  \n",
    "\n",
    "See section 2-2 for supporting documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_bad = df.Quantity[df.perish == 1]\n",
    "no_bad = df.Quantity[df.perish == 0]\n",
    "mannwhitneyu(no_bad,goes_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(no_bad,goes_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3 Results\n",
    "- Failed to reject the null hypothesis. The quantity ordered of perishable items _doesn't significantly change_ The quantity ordered of non-perishable items \n",
    "- (p-value > $\\alpha$ :: 0.3518 > 0.05)\n",
    "- Further testing: Reach out to the data engineers and obtain 'good until' dates and use that as a metric\n",
    "___\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESOUCES:\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3116565/\n",
    "\n",
    "https://pythonfordatascience.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
